from openai import OpenAI
import time
import jwt
import requests
import json

class Backend:
    def __init__(self, config=None):
        with open('config.json', encoding='utf-8') as f:
            self.config = json.load(f)
        self.client = OpenAI(
            api_key=self.config["kimi_api_key"],
            # TODO: add configuration file, ignore real config file in git while give an example config file (avoid leaking api key)
            base_url="https://api.moonshot.cn/v1")
        self.all_messages = []
        self.instruction_messages = [
            {"role": "user", "content": f'''你是一个文生图模型的提示词优化器。用户将告诉你他对图片的大概想法，你要将这些想法转化为高质量的提示词。你应与用户进行多轮对话，可以引导用户提供更多的细节。你最终要输出优化过的提示词。

以下是优秀的提示词所共有的元素，你输出的最终的提示词中要包含它们：

- 媒介。比如照片、插画、雕塑、壁画等。若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。
- 风格。若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。一些常见的风格词汇有：二次元、新海诚、宫崎骏、九十年代动漫、像素、赛博朋克、科幻机甲、涂鸦、水墨画、油画、插画、卡通、童话风格、迪士尼风、电影风格、现代风格、极简主义、油画、超现实主义、概念艺术、工业风格、扁平化设计、手写风格、手绘、雕刻艺术风格、游戏场景图、梵高、达芬奇、巴洛克时期、哥特式、科幻、魔幻现实、未来主义、维多利亚时代、新古典主义、乡村风格、像素风、动物森友会、国潮、复古未来主义、浮世绘、乐高、粉红公主、波普艺术、抽象技术、嬉皮士、矢量图、铅笔艺术、立体主义、野兽派风格、鬼魂风格、印象主义、卡哇伊风格、故障艺术、蒸汽波艺术、包豪斯艺术、表现主义……
- 主体。用户的输入中一定有画面主体，你需要把它挑出来。
- 主体细节。若用户最初没有提供画面主体相关的细节或细节较少，你可以指出一些能够添加细节的点，并让用户有选择性地添加细节。
- 环境。比如森林、城市、咖啡馆……若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。
- 镜头。包括长镜头，短镜头，全景三种。如果你比较确定的话，可以自己选择一种。如果你不确定，且用户一开始也没有提供此信息，你可以询问用户并给出你的推荐。
- 色彩。比如明亮、暗黑等。如果你比较确定的话，可以自己选择一种。如果你不确定，且用户一开始也没有提供此信息，你可以询问用户并给出你的推荐。
- 图片质量。如果用户没有提供此信息，你可以自己将其补充为“最佳质量，细节清晰，4k，大师作品”

你最好以上面列出的顺序寻找信息或引导用户提供信息。当你获得所有你需要的信息时，你还需要把它们进行适量简写，让提示词中的每个词都不要太长。当你通过对话已经得到了足够的信息来确定最终的提示词时，请先输出“这是优化后的最终的提示词：”，接下来应以以下顺序排列提示词并输出：【主体】【主体细节】【环境】【风格】【媒介】【镜头】【色彩】【图片质量】，不要输出别的任何东西。

如果你完全明白了上述指令，请输出“我准备好了！请提供你的原始输入，让我们开始对话。”接下来，用户将给出他的原始输入，你将开始与他对话并最终给出高质量的提示词。请注意，你必须与用户进行对话，不能直接给出提示词！'''},
            {"role": "assistant", "content": "我准备好了！请提供你的原始输入，让我们开始对话。"},
        ]
        self.all_messages.extend(self.instruction_messages)
        self.original_input = ''
        # self.already_finished = False
        self.LLM_cur_try_ended = False
        self.cur_prompt = ''
    
    def check_is_finished(self, llm_output):
        '''
        check whether the final prompt is in the llm_output
        '''
        # if "这是优化后的最终的提示词" in llm_output:
        if "优化" in llm_output and "最终" in llm_output and "提示词" in llm_output:
            print("check already finished True!", llm_output)
            return True
        return False
    
    def pick_prompt_from_response(self, llm_output):
        '''
        process the prompt organized by LLM, delete the unneccesary words before the actual prompt
        '''
        prompt = llm_output
        en_pos = prompt.rfind(':')
        zh_pos = prompt.rfind('：')
        pos = max(en_pos, zh_pos)
        if pos != -1:
            prompt = prompt[pos + 3:]
        prompt = prompt.replace(' ', '')
        return prompt
    
    def add_new_round_of_conversation(self, user_input):
        '''
        append user_input, and call LLM API to obtain LLM output
        ''' 
        self.all_messages.append({"role": "user", "content": user_input})
        response = self.client.chat.completions.create(
            model="moonshot-v1-8k",
            messages=self.all_messages,
            temperature=0.,
            max_tokens=500,
        )
        llm_output = response.choices[0].message.content
        self.all_messages.append({"role": "assistant", "content": llm_output})
        return llm_output
    
    def process_user_data(self, user_input, finish_button):
        '''
        connect with frontend
        user_input: the user input in the front end
        finish_button: whether the user want to end the conversation
        
        return: (response/prompt, False/True(whether the prompt is outputed), img_url/None)
        '''
        if self.LLM_cur_try_ended and finish_button: # just finished generating a quite good prompt, and user is satisfied with it
            img = self.generate_image(self.cur_prompt)
            return self.cur_prompt, True, img # return image to frontend for display
        
        self.LLM_cur_try_ended = False
        if finish_button: # if user wants to end the conversation and let LLM generate the rest
            if self.original_input == '':
                print("wrong! End too early!")
                return 'wrong! End too early!', False, None
            else:
                # recommand all the rest aspects
                while(1): # simulate the conversation, where the user input is always '推荐'
                    user_input = '推荐'
                    llm_output = self.add_new_round_of_conversation(user_input)
                    if self.check_is_finished(llm_output): # the final prompt is already generated by LLM
                        returned_prompt = self.add_new_round_of_conversation('以字符串方式输出提示词，不要有特殊字符，不同词汇用中文逗号分隔开。不要漏掉提示词文字信息。')
                        prompt = self.pick_prompt_from_response(returned_prompt)
                        self.LLM_cur_try_ended = True
                        self.cur_prompt = prompt
                        return prompt, True, None
                    
        if self.original_input == '':
            self.original_input = user_input
        llm_output = self.add_new_round_of_conversation(user_input)
        if self.check_is_finished(llm_output): # the final prompt is already generated by LLM
            returned_prompt = self.add_new_round_of_conversation('以字符串方式输出提示词，不要有特殊字符，不同词汇用中文逗号分隔开。不要漏掉提示词文字信息。')
            prompt = self.pick_prompt_from_response(returned_prompt)
            # self.LLM_first_try_ended = True
            self.LLM_cur_try_ended = True
            self.cur_prompt = prompt
            return prompt, True, None
        return llm_output, False, None
        
    def generate_image(self, prompt):
        ak = self.config["image_ak"]
        sk = self.config["image_sk"]
        # TODO: add config
        def encode_jwt_token(ak, sk):
            headers = {
                "alg": "HS256",
                "typ": "JWT"
            }
            payload = {
                "iss": ak,
                "exp": int(time.time()) + 1800, # 填写您期望的有效时间，此处示例代表当前时间+30分钟
                "nbf": int(time.time()) - 5 # 填写您期望的生效时间，此处示例代表当前时间-5秒
            }
            token = jwt.encode(payload, sk, headers=headers)
            return token
        
        authorization = encode_jwt_token(ak, sk)
        API_TOKEN = f"Bearer {authorization}"
        MODEL_ID = "sgl_artist_v0.3.5_0925"
        headers = {
            "Content-Type": "application/json",
            "Authorization": API_TOKEN
        }
        url = "https://api.sensenova.cn/v1/imgen/internal/generation_tasks"
        data = {
            "model_id": MODEL_ID,
            "prompt": prompt,
            "samples": 1,
            "cfg_scale": 7.0,
            "height": 960,
            "width": 960
        }
        print("ready to generate image with prompt", prompt)
        while True:
            response = requests.post(url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                print("任务ID:", result.get("task_id"))
                while True:
                    response = requests.get(url+f'/{result.get("task_id")}', headers=headers)
                    if response.json().get('task').get('state') != 'SUCCESS':
                        time.sleep(1)
                        print('wait 1s')
                    else:
                        break
                img_url = response.json().get('task').get('result')[0].get('raw')
                return img_url
            else:
                print("请求失败，状态码:", response.status_code)
                print("错误信息:", response.text)

if __name__ == '__main__':
    back = Backend()
    while(1):
        user_input = input("请输入文字:")
        finish = (input("是否结束(y/n):")) == 'y'
        print("front end input", user_input, finish)
        response, is_prompt, img_url = back.process_user_data(user_input, finish)
        if is_prompt:
            print("prompt is already generated! If you are ok with it, click finish", response, img_url)
        else:
            print(response)