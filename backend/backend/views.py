import json
import time
import jwt
import requests
from typing import Tuple
from openai import OpenAI
from django.http import JsonResponse, HttpRequest
from django.views.decorators.http import require_http_methods

with open('./backend/config.json', encoding='utf-8') as f:
    config = json.load(f)

def get_client() -> OpenAI:
    return OpenAI(
        api_key=config["kimi_api_key"],
        # TODO: add configuration file, ignore real config file in git while give an example config file (avoid leaking api key)
        base_url="https://api.moonshot.cn/v1"
    )

def pick_prompt_from_response(llm_output: str) -> str:
    '''
    process the prompt organized by LLM, delete the unneccesary words before the actual prompt
    '''
    prompt = llm_output
    en_pos = prompt.rfind(':')
    zh_pos = prompt.rfind('：')
    pos = max(en_pos, zh_pos)
    if pos != -1:
        prompt = prompt[pos + 3:]
    prompt = prompt.replace(' ', '')
    return prompt

def add_new_round_of_conversation(user_input: str, history: list, client: OpenAI = None) -> Tuple[str, OpenAI]:
    '''
    append user_input, and call LLM API to obtain LLM output
    ''' 
    if client is None:
        client = get_client()
    history.append({"role": "user", "content": user_input})
    response = client.chat.completions.create(
        model="moonshot-v1-8k",
        messages=history,
        temperature=0.,
        max_tokens=500,
    )
    llm_output = response.choices[0].message.content
    history.append({"role": "assistant", "content": llm_output})
    return llm_output, client

def check_is_finished(llm_output: str) -> bool:
    '''
    check whether the final prompt is in the llm_output
    '''
    # if "这是优化后的最终的提示词" in llm_output:
    # if "优化" in llm_output and "最终" in llm_output and "提示词" in llm_output:
    if "最终" in llm_output and "提示词" in llm_output:
        print("check already finished True!", llm_output)
        return True
    return False

def single_chat(user_input: str, history: list) -> Tuple[str, str | None, bool]:
    llm_output, client = add_new_round_of_conversation(user_input, history)
    if check_is_finished(llm_output): # the final prompt is already generated by LLM
        returned_prompt, client = add_new_round_of_conversation('以字符串方式输出提示词，不要有特殊字符，不同词汇用中文逗号分隔开。不要漏掉提示词文字信息。', history, client)
        # 英文标点
        prompt = pick_prompt_from_response(returned_prompt)
        return llm_output, prompt, True
    return llm_output, None, False

def generate_image(prompt):
    ak = config["image_ak"]
    sk = config["image_sk"]
    # TODO: add config
    def encode_jwt_token(ak, sk):
        headers = {
            "alg": "HS256",
            "typ": "JWT"
        }
        payload = {
            "iss": ak,
            "exp": int(time.time()) + 1800, # 填写您期望的有效时间，此处示例代表当前时间+30分钟
            "nbf": int(time.time()) - 5 # 填写您期望的生效时间，此处示例代表当前时间-5秒
        }
        token = jwt.encode(payload, sk, headers=headers)
        return token
    
    authorization = encode_jwt_token(ak, sk)
    API_TOKEN = f"Bearer {authorization}"
    MODEL_ID = "sgl_artist_v0.3.5_0925"
    headers = {
        "Content-Type": "application/json",
        "Authorization": API_TOKEN
    }
    url = "https://api.sensenova.cn/v1/imgen/internal/generation_tasks"
    data = {
        "model_id": MODEL_ID,
        "prompt": prompt,
        "samples": 1,
        "cfg_scale": 7.0,
        "height": 960,
        "width": 960
    }
    print("ready to generate image with prompt", prompt)
    while True:
        response = requests.post(url, headers=headers, json=data)
        if response.status_code == 200:
            result = response.json()
            print("任务ID:", result.get("task_id"))
            while True:
                response = requests.get(url+f'/{result.get("task_id")}', headers=headers)
                if response.json().get('task').get('state') != 'SUCCESS':
                    time.sleep(1)
                    print('wait 1s')
                else:
                    break
            img_url = response.json().get('task').get('result')[0].get('raw')
            return img_url
        else:
            print("请求失败，状态码:", response.status_code)
            print("错误信息:", response.text)

def fulfill_history(history: list) -> list:
    return [
        {
            "role": "user",
            "content":
f'''你是一个文生图模型的提示词优化器。用户将告诉你他对图片的大概想法，你要将这些想法转化为高质量的提示词。你应与用户进行多轮对话，可以引导用户提供更多的细节。你最终要输出优化过的提示词。

以下是优秀的提示词所共有的元素，你输出的最终的提示词中要包含它们：

- 媒介。比如照片、插画、雕塑、壁画等。若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。
- 风格。若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。一些常见的风格词汇有：二次元、新海诚、宫崎骏、九十年代动漫、像素、赛博朋克、科幻机甲、涂鸦、水墨画、油画、插画、卡通、童话风格、迪士尼风、电影风格、现代风格、极简主义、油画、超现实主义、概念艺术、工业风格、扁平化设计、手写风格、手绘、雕刻艺术风格、游戏场景图、梵高、达芬奇、巴洛克时期、哥特式、科幻、魔幻现实、未来主义、维多利亚时代、新古典主义、乡村风格、像素风、动物森友会、国潮、复古未来主义、浮世绘、乐高、粉红公主、波普艺术、抽象技术、嬉皮士、矢量图、铅笔艺术、立体主义、野兽派风格、鬼魂风格、印象主义、卡哇伊风格、故障艺术、蒸汽波艺术、包豪斯艺术、表现主义……
- 主体。用户的输入中一定有画面主体，你需要把它挑出来。
- 主体细节。若用户最初没有提供画面主体相关的细节或细节较少，你可以指出一些能够添加细节的点，并让用户有选择性地添加细节。
- 环境。比如森林、城市、咖啡馆……若用户最初没有提供此信息，则你需要询问用户并依据你的常识给出推荐。
- 镜头。包括长镜头，短镜头，全景三种。如果你比较确定的话，可以自己选择一种。如果你不确定，且用户一开始也没有提供此信息，你可以询问用户并给出你的推荐。
- 色彩。比如明亮、暗黑等。如果你比较确定的话，可以自己选择一种。如果你不确定，且用户一开始也没有提供此信息，你可以询问用户并给出你的推荐。
- 图片质量。如果用户没有提供此信息，你可以自己将其补充为“最佳质量，细节清晰，4k，大师作品”

你最好以上面列出的顺序寻找信息或引导用户提供信息。当你获得所有你需要的信息时，你还需要把它们进行适量简写，让提示词中的每个词都不要太长。当你通过对话已经得到了足够的信息来确定最终的提示词时，请先输出“这是优化后的最终的提示词：”，接下来应以以下顺序排列提示词并输出：主体，主体细节，环境，风格，媒介，镜头，色彩，图片质量，不要输出别的任何东西。

如果你完全明白了上述指令，请输出“我准备好了！请提供你的原始输入，让我们开始对话。”接下来，用户将给出他的原始输入，你将开始与他对话并最终给出高质量的提示词。请注意，你必须与用户进行对话，不能直接给出提示词！'''
        },
        {
            "role": "assistant",
            "content": "我准备好了！请提供你的原始输入，让我们开始对话。"
        },
    ] + history

@require_http_methods(["GET"])
def chat(request: HttpRequest) -> JsonResponse:
    body = json.loads(request.body.decode())
    history = fulfill_history(body['history'])
    response, prompt, is_end = single_chat(body['user_input'], history)
    return JsonResponse({
        'response': response,
        'prompt': prompt,
        'is_end': is_end,
    })
    
@require_http_methods(["GET"])
def finish(request: HttpRequest) -> JsonResponse:
    '''
    request body: {
        'history': list,
        'prompt': str
    }
    return: {
        'img_generated': bool,
        'img_url': str,
        'prompt': str,
        'response': str,
    }
    '''
    body = json.loads(request.body.decode())
    history = fulfill_history(body['history'])
    prompt = body['prompt']
    
    if prompt is not None:
        return JsonResponse({
            'img_generated': True,
            'img_url': generate_image(prompt)
        })
    
    while True: # simulate the conversation, where the user input is always '推荐'
        user_input = '推荐'
        response, prompt, is_end = single_chat(user_input, history)
        if is_end:
            return JsonResponse({
                'img_generated': False,
                'prompt': prompt,
                'response': response,
            })
        